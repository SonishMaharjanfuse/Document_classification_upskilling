{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGHdrkUtqNpS"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1FehewnjdHb5Tu-ZeP_FcQqqAGdwgPDN8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rddS5yE0qhRA"
      },
      "outputs": [],
      "source": [
        "!unzip doc_classification.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing required library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ulj_X7BqpIN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Onq9cozOqrDM"
      },
      "outputs": [],
      "source": [
        "# Define your dataset directories\n",
        "train_dir = \"/content/data/train\"\n",
        "validation_dir = \"/content/data/validation\"\n",
        "\n",
        "# Define the input shape expected by VGG19\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Load the VGG19 model with pre-trained weights (exclude the top dense layers)\n",
        "base_model = VGG19(weights='imagenet', include_top=False,\n",
        "                   input_shape=input_shape)\n",
        "\n",
        "# Freeze the convolutional layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IDRsDtiqyf2"
      },
      "outputs": [],
      "source": [
        "# Build a new model on top of VGG19\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "# Adjust the number of output classes based on your dataset\n",
        "model.add(layers.Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2aHoZIvq2Uu"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSs8hUQBq9G0"
      },
      "outputs": [],
      "source": [
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Validation data should not be augmented\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlGZdYE0rAqK"
      },
      "outputs": [],
      "source": [
        "# Create generators for training and validation data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'  # Use 'categorical' for multi-class classification\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJUSSyZYrDGH"
      },
      "outputs": [],
      "source": [
        "# Create checkpoint for saving best modle\n",
        "checkpoint_filepath = 'ckpt'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQMewRYzrF2E"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "epochs = 5  # Adjust the number of epochs based on your dataset and computational resources\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[model_checkpoint_callback],\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4orb9nLHrJCm"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C-ItldYql1y"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model.save(\"vgg19_model_multiclass.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QQbS6tyrff_"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained model\n",
        "# model = load_model(\"/content/vgg19_model_multiclass.keras\")\n",
        "class_names = ['citizenship', 'license', 'passport']\n",
        "\n",
        "\n",
        "def predict(img):\n",
        "    image = cv2.imread(img)\n",
        "\n",
        "    # Resize the image\n",
        "    resized_image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Add an extra dimension to match the expected input shape of the model\n",
        "    input_image = np.expand_dims(resized_image, axis=0)\n",
        "\n",
        "    # Assuming model is a pre-trained VGG16 model\n",
        "    model = tf.keras.models.load_model(\"/content/ckpt\")\n",
        "    predictions = model.predict(input_image)[0]\n",
        "\n",
        "    # Get the index of the predicted class\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "    # Get the class name based on the index\n",
        "    predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "    print(\"Predicted Class:\", predicted_class_name)\n",
        "    print(\"Predicted Probabilities:\", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1D--C47rMuc"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "image_path = \"/content/test2.jpeg\"\n",
        "predict(image_path)\n",
        "PIL.Image.open(image_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
